# 📚 Hugging Face 기반 문서 요약 (News 데이터)

Hugging Face Transformers를 사용해 한국어 문서 요약 파이프라인을 구축한 프로젝트입니다.  
데이터 로드 및 전처리부터 토크나이징, 요약 생성(또는 파인튜닝), ROUGE 평가까지 전체 흐름을 구성했습니다.

---

## 미션 요구사항 요약

- 문서 데이터 로드 및 전처리
- Transformers 기반 요약 모델 실행
- 생성 요약문 평가(ROUGE 등) 및 결과 분석
- 노트북 내 마크다운으로 워크플로우를 이해하기 쉽게 정리

---

## 사용 데이터

원본 데이터는 3종류 문서 타입으로 제공됩니다.

- news (신문 기사)
- editorial (사설)
- law (법률)

이번 프로젝트에서는 news만 사용했습니다.

- train: 243,983
- valid: 30,122

---

## EDA 결과 요약 (News train 기준)

원문/요약 길이 특성을 먼저 확인했습니다.

- text 평균 길이: 약 1,005자 (중앙값 932자)
- summary 평균 길이: 약 128자
- text 최대 길이: 14,791자 (초장문 outlier 존재)

의미:
- 대부분은 적당한 길이지만,
- 일부 초장문은 모델 입력 길이 제한(max_length)에서 잘릴 수 있어
  요약 품질에 영향을 줄 가능성이 있습니다.

---

## 전체 파이프라인

1. JSON 로드 (news만 선택)
2. 텍스트 전처리 (불필요 공백/기호 정리)
3. 토크나이징 (원문/요약 인코딩)
4. 모델 실행 (요약 생성 또는 파인튜닝)
5. 평가 (ROUGE, 샘플 비교)

---

## 결과 및 결론 (ROUGE 비교)

뉴스(news) 데이터만 사용하여 입력 길이 제한(512 토큰) 환경에서 2가지 전략을 비교했습니다.

- 실험 1: Standard Truncation (앞에서부터 512 토큰으로 자르기)
- 실험 2: Head-Tail Strategy (앞+뒤를 가져와 정보 손실을 줄이기)

정량 평가(ROUGE, News 샘플 100 기준) 결과는 아래와 같습니다.

- 실험 1 (Standard)
  - ROUGE-1: 0.5149
  - ROUGE-2: 0.2107
  - ROUGE-L: 0.4878

- 실험 2 (Head-Tail)
  - ROUGE-1: 0.5009
  - ROUGE-2: 0.1985
  - ROUGE-L: 0.4749

결론적으로, 세 지표 모두에서 **Standard Truncation이 더 높은 성능**을 보였습니다.  
이는 뉴스 기사 특성상 핵심 정보가 앞부분에 위치하는 경우가 많아(두괄식),
앞부분을 안정적으로 유지하는 전략이 더 유리하게 작동했기 때문으로 해석했습니다.

다만, 법률/사설처럼 결론이 뒤에 몰리는 도메인에서는 Head-Tail 전략이 유리해질 수 있어,
도메인별 전략 비교 실험을 추가로 진행하는 것이 좋습니다.

